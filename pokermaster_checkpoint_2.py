# -*- coding: utf-8 -*-
"""PokerMaster-checkpoint_2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UrNidLJ-E__0vyJnvXHYrBgVa-4ht2iz
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.naive_bayes import GaussianNB, MultinomialNB
from sklearn.metrics import accuracy_score
from sklearn.model_selection import KFold, train_test_split, StratifiedKFold

"""### About the Data

![Alt text](https://farm4.staticflickr.com/3585/3299226824_4637597b74_z_d.jpg "Cards by bl0ndeeo2, Creative Commons License (https://flic.kr/p/62xpc7) ")

The [dataset](http://archive.ics.uci.edu/ml/datasets/Poker+Hand) we'll be exploring in this post is the Poker Hand data from the UCI Machine Learning Repository.

Each record in the dataset is an example of a hand consisting of five playing cards drawn from a standard deck of 52. Each card is described using two attributes (suit and rank), for a total of 10 predictive attributes. The target column describes the hand, with the possibilities being:    

    0: Nothing in hand; not a recognized poker hand     
    1: One pair; one pair of equal ranks within five cards     
    2: Two pairs; two pairs of equal ranks within five cards     
    3: Three of a kind; three equal ranks within five cards     
    4: Straight; five cards, sequentially ranked with no gaps     
    5: Flush; five cards with the same suit     
    6: Full house; pair + different rank three of a kind     
    7: Four of a kind; four equal ranks within five cards     
    8: Straight flush; straight + flush     
    9: Royal flush; {Ace, King, Queen, Jack, Ten} + flush     
    
The order of cards is important, which is why there are 480 possible Royal Flush hands as compared to 4 (one for each suit).
"""

from google.colab import drive
drive.mount('/content/drive')

train=pd.read_csv('/content/drive/My Drive/TEC_9_Sem/Sistemas Inteligentes/poker-hand-training-true .data',header=None)
test = pd.read_csv('/content/drive/My Drive/TEC_9_Sem/Sistemas Inteligentes/poker-hand-testing.data',header=None)

train.columns =['S1', 'C1','S2', 'C2','S3', 'C3','S4', 'C4','S5', 'C5','Hand']
test.columns = ['S1', 'C1','S2', 'C2','S3', 'C3','S4', 'C4','S5', 'C5','Hand']

train.head()

train.shape

test.shape

X_train = train.loc[:,train.columns != 'Hand']
X_test = test.loc[:,test.columns != 'Hand']
Y_train = train['Hand']
Y_test = test['Hand']

"""### Separate the Data into Features and Targets

### Evaluating Class Balance
"""

from yellowbrick.classifier import ClassBalance, ROCAUC, ClassificationReport, ClassPredictionError
balance = ClassBalance(size=(1080, 720), Y_train=train)

balance.fit(Y_train)   
#balance.score(X, y)
balance.poof()

Y_train.groupby(Y_train).size()

from yellowbrick.classifier import ClassBalance, ROCAUC, ClassificationReport, ClassPredictionError
balance = ClassBalance(size=(1080, 720), Y_test=test)

balance.fit(Y_test)   
#balance.score(X, y)
balance.poof()

Y_test.groupby(Y_test).size()

"""Training the Random Forests Classifier

### Training the Random Forests Classifier
"""

from sklearn.model_selection import train_test_split as tts
from sklearn.ensemble import RandomForestClassifier
from sklearn import metrics

clf= DecisionTreeClassifier(random_state=1, criterion='gini')


clf.fit(X_train, Y_train)
Y_pred = clf.predict(X_test)
# Model Accuracy, how often is the classifier correct?
print("Accuracy:",metrics.accuracy_score(Y_test, Y_pred))

"""Preprocess the Data to sort the values"""

def preprocess_data(data:pd.DataFrame):
    df = data.copy()
    dfc = df[['C1', 'C2', 'C3', 'C4', 'C5']]
    dfc.values.sort()
    df[['C1', 'C2', 'C3', 'C4', 'C5']] = dfc
    df = df[['C1', 'C2', 'C3', 'C4', 'C5', 'S1', 'S2', 'S3', 'S4', 'S5', 'Hand']]
    return df

X_train_pre = preprocess_data(train)
X_test_pre = preprocess_data(test)
X_train = X_train_pre.loc[:,X_train_pre.columns != 'Hand']
X_test = X_test_pre.loc[:,X_test_pre.columns != 'Hand']

"""### Classification Accuracy"""

from sklearn.model_selection import train_test_split as tts
from sklearn.ensemble import RandomForestClassifier

clf= DecisionTreeClassifier(random_state=1, criterion='gini')


clf.fit(X_train, Y_train)
y_pred = clf.predict(X_test)
# Model Accuracy, how often is the classifier correct?
print("Accuracy:",metrics.accuracy_score(Y_test, y_pred))

"""### ROC Curve and AUC"""

from yellowbrick.classifier import ROCAUC, ClassificationReport, ClassPredictionError
labels = ['zilch', 'one_pair', 'two_pair', 'three_of_a_kind', 'straight', 'flush', 'full_house',
           'four_of_a_kind', 'straight_flush', 'royal_flush']
rocauc = ROCAUC(clf, size=(1080, 720), classes=labels)

rocauc.score(X_test, Y_test)  
r = rocauc.poof()

"""### Classification Report Heatmap"""

report = ClassificationReport(clf, size=(720, 640), classes=labels, cmap='PuBu')

report.score(X_test, Y_test)
c = report.poof()

"""### Class Prediction Error"""

error = ClassPredictionError(clf, size=(1080, 720), classes=labels)

error.score(X_test, Y_test)
e = error.poof()

pred_series = pd.Series(y_pred).groupby(y_pred).size()
true_series = pd.Series(Y_test.values).groupby(Y_test).size()
pred_res = pd.DataFrame()
pred_res['TrueLabel'] = true_series
pred_res['PredictedLabel'] = pred_series
pred_res

f, ax = plt.subplots()
ax.set(yscale="log")
sns.barplot(data=pred_res.stack().reset_index().rename(columns={0: 'Count', 'level_1': 'Variable'}), x='Hand', y='Count', hue='Variable')

"""### Make Unique for hands with 5 carts"""

def add_unique_count(df:pd.DataFrame):
    tmp = df[['S1', 'S2', 'S3', 'S4', 'S5']]
    df['UniqueS'] = tmp.apply(lambda x: len(np.unique(x)) , axis=1)

add_unique_count(X_test)

add_unique_count(X_train)

X_train.head()

clf1= DecisionTreeClassifier(random_state=1, criterion='gini')

clf1.fit(X_train, Y_train)

y_pred = clf1.predict(X_test)
# Model Accuracy, how often is the classifier correct?
print("Accuracy:",metrics.accuracy_score(Y_test, y_pred))

pred_series = pd.Series(y_pred).groupby(y_pred).size()
true_series = pd.Series(Y_test.values).groupby(Y_test).size()
pred_res = pd.DataFrame()
pred_res['TrueLabel'] = true_series
pred_res['PredictedLabel'] = pred_series
f, ax = plt.subplots()
ax.set(yscale="log")
sns.barplot(data=pred_res.stack().reset_index().rename(columns={0: 'Count', 'level_1': 'Variable'}), x='Hand', y='Count', hue='Variable')

report = ClassificationReport(clf1, size=(720, 640), classes=labels, cmap='PuBu')

report.score(X_test, Y_test)
c = report.poof()

"""Now we will add new features with values of differences between consecutive cards in hand."""

def add_diffs(df:pd.DataFrame):
    df['Diff1'] = df['C5'] - df['C4']
    df['Diff2'] = df['C4'] - df['C3']
    df['Diff3'] = df['C3'] - df['C2']
    df['Diff4'] = df['C2'] - df['C1']

add_diffs(X_train)

add_diffs(X_test)

X_train.head()

clf2= DecisionTreeClassifier(random_state=1, criterion='gini')

clf2.fit(X_train, Y_train)

y_pred = clf2.predict(X_test)
# Model Accuracy, how often is the classifier correct?
print("Accuracy:",metrics.accuracy_score(Y_test, y_pred))

pred_series = pd.Series(y_pred).groupby(y_pred).size()
true_series = pd.Series(Y_test.values).groupby(Y_test).size()
pred_res = pd.DataFrame()
pred_res['TrueLabel'] = true_series
pred_res['PredictedLabel'] = pred_series

f, ax = plt.subplots()
ax.set(yscale="log")
sns.barplot(data=pred_res.stack().reset_index().rename(columns={0: 'Count', 'level_1': 'Variable'}), x='Hand', y='Count', hue='Variable')

report = ClassificationReport(clf2, size=(720, 640), classes=labels, cmap='PuBu')

report.score(X_test, Y_test)
c = report.poof()

"""Random Forest Application"""

rf = RandomForestClassifier(criterion='gini', n_estimators=10, random_state=111, n_jobs=4)

rf.fit(X_train, Y_train)

yf_pred = rf.predict(X_test)

# Model Accuracy, how often is the classifier correct?
print("Accuracy:",metrics.accuracy_score(Y_test, yf_pred))

pred_series = pd.Series(yf_pred).groupby(yf_pred).size()
true_series = pd.Series(Y_test.values).groupby(Y_test).size()
pred_res = pd.DataFrame()
pred_res['TrueLabel'] = true_series
pred_res['PredictedLabel'] = pred_series
pred_series

f, ax = plt.subplots()
ax.set(yscale="log")
sns.barplot(data=pred_res.stack().reset_index().rename(columns={0: 'Count', 'level_1': 'Variable'}), x='Hand', y='Count', hue='Variable')

report = ClassificationReport(rf, size=(720, 640), classes=labels, cmap='PuBu')

report.score(X_test, Y_test)
c = report.poof()

def predictionForest(X_test, rf):
    yf_pred = rf.predict(X_test)
    #print(yf_pred)
    return yf_pred

def predictionThree1(X_test, clf1):
    yt1_pred = clf1.predict(X_test)
    #print(yf_pred)
    return yt1_pred

def predictionThree2(X_test, clf2):
    yt2_pred = clf2.predict(X_test)
    #print(yf_pred)
    return yt2_pred

def preprocess_dataT(data:pd.DataFrame):
    df = data.copy()
    dfc = df[['C1', 'C2', 'C3', 'C4', 'C5']]
    dfc.values.sort()
    df[['C1', 'C2', 'C3', 'C4', 'C5']] = dfc
    df = df[['C1', 'C2', 'C3', 'C4', 'C5', 'S1', 'S2', 'S3', 'S4', 'S5']]
    return df

#Suit (1-4) representing {Hearts, Spades, Diamonds, Clubs}
#Numerical (1-13) representing (Ace, 2, 3, ... , Queen, King)

Eti= ['S1', 'C1','S2', 'C2','S3', 'C3','S4', 'C4','S5', 'C5']
X1_test1=np.array([[1,1,2,1,3,1,4,1,2,2],#4 ACES + 2 of SPADES 7
                   [1,1,1,2,1,3,1,4,1,5],#Straight Flush 8
                   [1,1,1,13,1,12,1,11,1,10], #Royal Flush 9 
                   [2,2,3,2,4,2,1,4,2,4], #Full House 6
                   [2,4,2,6,2,10,2,12,2,7], #Flush 5
                   [1,2,2,3,3,4,1,5,4,6], #Straight 4
                   [1,6,2,6,3,6,1,1,4,7], #Three of Kind 3
                   [4,5,3,5,2,13,2,1,3,13], #TwoPair 2
                   [3,6,3,7,4,7,1,13,1,10], #One Pair 1
                   [1,2,3,4,2,6,1,9,1,10] #Nothing 0
                   ])


X1_test=pd.DataFrame(X1_test1,columns=Eti)



preprocess_dataT(X1_test)
add_unique_count(X1_test)

#yThree1=predictionThree1(X1_test,clf1)

add_diffs(X1_test)

yThree2=predictionThree2(X1_test,clf2)
yForest=predictionForest(X1_test,rf)

Hand=['Nothing','One Pair','Two Pair','Three of Kind','Straight','Flush','Full House','Poker','Straight Flush','Royal Flush']

print("Random Forest ",yForest)
#print("First Three   ",yThree1)
print("Second Three  ",yThree2)
X1_test.head(10)